{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset set contained in four text files consists of tweets for four different emotions: anger, fear, joy and sadness.<br>\n",
    "\n",
    "Along with the tweet, the intensity or degree of emotion X felt by the speaker (a real-valued score between 0 and 1) is also provided. <br>\n",
    "\n",
    "The maximum possible score 1 stands for feeling the maximum amount of emotion X (or having a mental state maximally inclined towards feeling emotion X). The minimum possible score 0 stands for feeling the least amount of emotion X (or having a mental state maximally away from feeling emotion X). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals: \n",
    "i) To classify a given tweet into one of the four classes: anger, fear, joy or sadness. <br>\n",
    "ii) To display the degree of the classified emotion in the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing required package:<br>\n",
    "```\n",
    "pip3 install nltk\n",
    " (or)\n",
    "pip install nltk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone the N word. If I wasn't in a moving vehicle I'd have jumped out #disgusted</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered to a pick up store not my address #fuming #poorcustomerservice</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alarm in davis bc I was sound asleep #pissed #angry #upset #tired #sad #tired #hangry ######</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on you, talk over you and are rude. Taking money out of my acc willynilly! #fuming</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  \\\n",
       "0  10000   \n",
       "1  10001   \n",
       "2  10002   \n",
       "3  10003   \n",
       "4  10004   \n",
       "\n",
       "                                                                                                                                    tweet  \\\n",
       "0  How the fu*k! Who the heck! moved my fridge!... should I knock the landlord door. #angry #mad ##                                         \n",
       "1  So my Indian Uber driver just called someone the N word. If I wasn't in a moving vehicle I'd have jumped out #disgusted                  \n",
       "2  @DPD_UK I asked for my parcel to be delivered to a pick up store not my address #fuming #poorcustomerservice                             \n",
       "3  so ef whichever butt wipe pulled the fire alarm in davis bc I was sound asleep #pissed #angry #upset #tired #sad #tired #hangry ######   \n",
       "4  Don't join @BTCare they put the phone down on you, talk over you and are rude. Taking money out of my acc willynilly! #fuming            \n",
       "\n",
       "  emotion  intensity  \n",
       "0  anger   0.938      \n",
       "1  anger   0.896      \n",
       "2  anger   0.896      \n",
       "3  anger   0.896      \n",
       "4  anger   0.896      "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "data = [] # Tweets\n",
    "data_labels = [] # Emotion label (anger, fear, joy, or sadness)\n",
    "data_int = [] # Intensityy of each emotion\n",
    "\n",
    "dataset=pd.read_csv(\"training_set/anger-ratings-0to1.train.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "\n",
    "# Display first few examples\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the tweets and their corresponding emotion and intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "data = [] # Tweets\n",
    "data_labels = [] # Emotion label (anger, fear, joy, or sadness)\n",
    "data_int = [] # Intensityy of each emotion\n",
    "\n",
    "dataset=pd.read_csv(\"training_set/anger-ratings-0to1.train.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('anger')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "    \n",
    "dataset=pd.read_csv(\"training_set/fear-ratings-0to1.train.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('fear')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "\n",
    "dataset=pd.read_csv(\"training_set/joy-ratings-0to1.train.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('joy')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "\n",
    "dataset=pd.read_csv(\"training_set/sadness-ratings-0to1.train.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('sadness')\n",
    "    data_int.append(dataset.iat[i,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "dv = []\n",
    "dl = []\n",
    "di = []\n",
    "index_shuf = list(range(len(data)))\n",
    "shuffle(index_shuf)\n",
    "for i in index_shuf:\n",
    "    dv.append(data[i])\n",
    "    dl.append(data_labels[i])\n",
    "    di.append(data_int[i])\n",
    "data = dv\n",
    "data_labels = dl\n",
    "data_int = di\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer = 'word',\n",
    "    lowercase = False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is great', 'This is too great to be great', 'THIS IS GREAT!']\n"
     ]
    }
   ],
   "source": [
    "example = ['this is great','This is too great to be great','THIS IS GREAT!']\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'GREAT', u'IS', u'THIS', u'This', u'be', u'great', u'is', u'this', u'to', u'too']\n",
      "[[0.         0.         0.         0.         0.         0.51785612\n",
      "  0.51785612 0.68091856 0.         0.        ]\n",
      " [0.         0.         0.         0.38091445 0.38091445 0.57939052\n",
      "  0.28969526 0.         0.38091445 0.38091445]\n",
      " [0.57735027 0.57735027 0.57735027 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "features_eg = vectorizer.fit_transform(\n",
    "    example\n",
    ")\n",
    "features_nd_eg = features_eg.toarray() # for easy usage\n",
    "print(vectorizer.get_feature_names())\n",
    "print(features_nd_eg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting features from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(\n",
    "    data\n",
    ")\n",
    "features_nd = features.toarray() # for easy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd, \n",
    "        data_labels,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3613, 11239)\n",
      "  (0, 10479)\t0.4314976665434786\n",
      "  (0, 7584)\t0.902114052527469\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.shape(features_nd))\n",
    "print((vectorizer.transform([\"I love to \"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "y_pred[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7800829875518672"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(y_pred==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fear', ':', 'Because it was a perfect illusion, but at least now I know what it was.  #ladygaga #iscalming#mysoul')\n",
      "('sadness', ':', \"And I won't even get started with Hillary and her fancy fundraisers! #depressing\")\n",
      "('fear', ':', 'induction day tomorrow for pizza express')\n",
      "('fear', ':', 'a panic attack AND CALL YOURSELF A REAL FAN makes me so mad like i dont even have the words to explain. this is why some people give no +')\n",
      "('joy', ':', '@alphavenger all chuck seasons, she had that one bright spot with dan, where she was allowed to be smart and kind //and// fashionable')\n",
      "('anger', ':', \"Don't be bitter\")\n",
      "('anger', ':', '@ChurdAllan fucked my coupon that goal!')\n"
     ]
    }
   ],
   "source": [
    "# Printing the predictions for some random test data\n",
    "import random\n",
    "\n",
    "j = random.randint(0,len(X_test)-7)\n",
    "for i in range(j,j+7):\n",
    "    ind = features_nd.tolist().index(X_test[i].tolist())\n",
    "    print(y_pred[i],\":\",data[ind].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7579529737206085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "```\n",
    "There are two sets each containing 4 files for each emotion provided for training and development. \n",
    "Combine these two sets for training and use 5-fold cross-validation \n",
    "to find out the Accuracy in all the cases mentioned below.\n",
    "```\n",
    "\n",
    "1. Calculate the accuracy using Random Forest Classifier and tune the number of estimators to get the best results. Comment on the same.\n",
    "2. Now use Logistic Regression and observe the accuracy value. Can the performance be further improved by using L1 and L2 regularizations?\n",
    "3. Repeat the same using Support Vector Classifier.\n",
    "4. Estimate the training & testing time for each classifier and comment on the results.\n",
    "5. Now, the emotion intensity score for each tweet is to be found on top of classification. To do this, fit different regression models on the training set for each emotion and find the emotion intensity score for each of the test set. Also, display mean square error for test set.\n",
    "6. In all the above cases, create a user-defined function, which takes a tweet (text) as input and displays the predicted emotion.\n",
    "7. A separate test set is provided. Use one of the classification models implemented earlier to determine the corresponding emotion for each tweet in this set. Use the linear regression models to calculate the emotional intensity.\n",
    "\n",
    "```In all the above cases, use a feature extractor other than CountVectorizer and observe performance.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset=pd.read_csv(\"dev_set/anger-ratings-0to1.dev.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('anger')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "    \n",
    "dataset=pd.read_csv(\"dev_set/fear-ratings-0to1.dev.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('fear')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "\n",
    "dataset=pd.read_csv(\"dev_set/joy-ratings-0to1.dev.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('joy')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "\n",
    "dataset=pd.read_csv(\"dev_set/sadness-ratings-0to1.dev.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('sadness')\n",
    "    data_int.append(dataset.iat[i,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "dv = []\n",
    "dl = []\n",
    "di = []\n",
    "index_shuf = list(range(len(data)))\n",
    "shuffle(index_shuf)\n",
    "for i in index_shuf:\n",
    "    dv.append(data[i])\n",
    "    dl.append(data_labels[i])\n",
    "    di.append(data_int[i])\n",
    "data = dv\n",
    "data_labels = dl\n",
    "data_int = di\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer = 'word',\n",
    "    lowercase = False,\n",
    ")\n",
    "\n",
    "features = vectorizer.fit_transform(\n",
    "    data\n",
    ")\n",
    "features_nd = features.toarray() # for easy usage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd, \n",
    "        data_labels,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.323373885956241"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_anger = []\n",
    "features_fear = []\n",
    "features_joy = []\n",
    "features_sadness = []\n",
    "\n",
    "data_int_anger = []\n",
    "data_int_fear = []\n",
    "data_int_joy = []\n",
    "data_int_sadness = []\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    if data_labels[i] == 'anger':\n",
    "        features_anger.append(features_nd[i])\n",
    "        data_int_anger.append(data_int[i])\n",
    "    if data_labels[i] == 'fear':\n",
    "        features_fear.append(features_nd[i])\n",
    "        data_int_fear.append(data_int[i])\n",
    "    if data_labels[i] == 'sadness':\n",
    "        features_sadness.append(features_nd[i])\n",
    "        data_int_sadness.append(data_int[i])\n",
    "    if data_labels[i] == 'joy':\n",
    "        features_joy.append(features_nd[i])\n",
    "        data_int_joy.append(data_int[i])\n",
    "\n",
    "sum(features_joy[8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73858268 0.74921136 0.74921136 0.73933649 0.75316456]\n",
      "('time taken:', 13.826820850372314)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "clf = RandomForestClassifier()\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "clf.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(scores)\n",
    "print(\"time taken:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797979797979798\n",
      "3.09264802933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd, \n",
    "        data_labels,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(clf.score(X_test,y_test))\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search on Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tg7797/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/tg7797/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100}\n",
      "0.833017676768\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "start = time.time()\n",
    "param_grid = {'n_estimators' : [10, 20, 50,100,150,200]}\n",
    "gridsearch_rf = GridSearchCV(clf, param_grid, n_jobs=-1,cv=5)\n",
    "gridsearch_rf.fit(X_train,y_train)\n",
    "print(gridsearch_rf.best_params_)\n",
    "print(gridsearch_rf.best_score_)\n",
    "end = time.time()\n",
    "print(\"Time taken:\"end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65649986267\n",
      "[0.72755906 0.75709779 0.74290221 0.75513428 0.78481013]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd, \n",
    "        data_labels,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "\n",
    "start = time.time()\n",
    "lr.fit(X_train,y_train)\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.00942206383\n",
      "[0.77952756 0.81230284 0.82938389 0.83254344 0.82148499]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_l1 = LogisticRegression(penalty='l1')\n",
    "\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd, \n",
    "        data_labels,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "\n",
    "start = time.time()\n",
    "lr_l1.fit(X_train,y_train)\n",
    "scores = cross_val_score(lr_l1, X_train, y_train, cv=5)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42507004738\n",
      "[0.70866142 0.76971609 0.77093207 0.7535545  0.73459716]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_l2 = LogisticRegression(penalty='l2')\n",
    "\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd, \n",
    "        data_labels,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "\n",
    "start = time.time()\n",
    "lr_l2.fit(X_train,y_train)\n",
    "scores = cross_val_score(lr_l2, X_train, y_train, cv=5)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that using L1 regularization (equivalent to Lasso) gives slightly better performance due to the high number of training features in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756.288990974\n",
      "[0.32598425 0.32492114 0.32492114 0.32543444 0.32594937]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "start = time.time()\n",
    "scores = cross_val_score(svc, X_train, y_train, cv=5)\n",
    "svc.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that the accuracy of SVC is the lowest while the training time for SVC is the highest. It can be seen that the L1 regularization increases the accuracy of the Logistic Regression while increasing the n_estimators increases the accuracy of the Random Forest classifier. The time taken by Logist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Regression models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Linear Regression gave very high MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lasso anger MSE', 0.02866396602717718)\n",
      "('Lasso fear MSE', 0.04180730119399449)\n",
      "('Lasso sadness MSE', 0.03753981642948891)\n",
      "('Lasso joy MSE', 0.0422497288103531)\n",
      "1.46816301346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "\n",
    "lasso_anger = Lasso()\n",
    "lasso_fear = Lasso()\n",
    "lasso_sadness = Lasso()\n",
    "lasso_joy = Lasso()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_anger, \n",
    "        data_int_anger,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "lasso_anger.fit(X_train,y_train)\n",
    "y_pred = lasso_anger.predict(X_test)\n",
    "print(\"Lasso anger MSE\",mean_squared_error(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_fear, \n",
    "        data_int_fear,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "lasso_fear.fit(X_train,y_train)\n",
    "y_pred = lasso_fear.predict(X_test)\n",
    "print(\"Lasso fear MSE\",mean_squared_error(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_sadness, \n",
    "        data_int_sadness,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "lasso_sadness.fit(X_train,y_train)\n",
    "y_pred = lasso_sadness.predict(X_test)\n",
    "print(\"Lasso sadness MSE\",mean_squared_error(y_test,y_pred))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_joy, \n",
    "        data_int_joy,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "lasso_joy.fit(X_train,y_train)\n",
    "y_pred = lasso_joy.predict(X_test)\n",
    "print(\"Lasso joy MSE\",mean_squared_error(y_test,y_pred))\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RFR anger MSE', 0.020250077671957675)\n",
      "('RFR anger train MSE', 0.005179754574468085)\n",
      "('RFR fear MSE', 0.02522518808173501)\n",
      "('RFR fear train MSE', 0.0044942089547401875)\n",
      "('RFR sadness MSE', 0.026548505813953488)\n",
      "('RFR sadness train MSE', 0.004292203488372093)\n",
      "('RFR joy MSE', 0.03518506908313167)\n",
      "('RFR joy train MSE', 0.0057021593241565)\n",
      "22.8726279736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr_anger = RandomForestRegressor(n_estimators = 5)\n",
    "rfr_fear = RandomForestRegressor()\n",
    "rfr_sadness = RandomForestRegressor()\n",
    "rfr_joy = RandomForestRegressor()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_anger, \n",
    "        data_int_anger,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "rfr_anger.fit(X_train,y_train)\n",
    "y_pred = rfr_anger.predict(X_test)\n",
    "print(\"RFR anger MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = rfr_anger.predict(X_train)\n",
    "print(\"RFR anger train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_fear, \n",
    "        data_int_fear,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "rfr_fear.fit(X_train,y_train)\n",
    "y_pred = rfr_fear.predict(X_test)\n",
    "print(\"RFR fear MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = rfr_fear.predict(X_train)\n",
    "print(\"RFR fear train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_sadness, \n",
    "        data_int_sadness,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "rfr_sadness.fit(X_train,y_train)\n",
    "y_pred = rfr_sadness.predict(X_test)\n",
    "print(\"RFR sadness MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = rfr_sadness.predict(X_train)\n",
    "print(\"RFR sadness train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_joy, \n",
    "        data_int_joy,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "rfr_joy.fit(X_train,y_train)\n",
    "y_pred = rfr_joy.predict(X_test)\n",
    "print(\"RFR joy MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = rfr_joy.predict(X_train)\n",
    "print(\"RFR joy train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVR anger MSE', 0.02862764165920558)\n",
      "('SVR anger train MSE', 0.028026568051555557)\n",
      "('SVR fear MSE', 0.04175611458489101)\n",
      "('SVR fear train MSE', 0.03648529068366911)\n",
      "('SVR sadness MSE', 0.037908530474595865)\n",
      "('SVR sadness train MSE', 0.03559074540435568)\n",
      "('SVR joy MSE', 0.042360697389192965)\n",
      "('SVR joy train MSE', 0.04218901209859038)\n",
      "50.182587862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_anger = SVR()\n",
    "svr_fear = SVR()\n",
    "svr_sadness = SVR()\n",
    "svr_joy = SVR()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_anger, \n",
    "        data_int_anger,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "svr_anger.fit(X_train,y_train)\n",
    "y_pred = svr_anger.predict(X_test)\n",
    "print(\"SVR anger MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = svr_anger.predict(X_train)\n",
    "print(\"SVR anger train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_fear, \n",
    "        data_int_fear,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "svr_fear.fit(X_train,y_train)\n",
    "y_pred = svr_fear.predict(X_test)\n",
    "print(\"SVR fear MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = svr_fear.predict(X_train)\n",
    "print(\"SVR fear train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_sadness, \n",
    "        data_int_sadness,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "svr_sadness.fit(X_train,y_train)\n",
    "y_pred = svr_sadness.predict(X_test)\n",
    "print(\"SVR sadness MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = svr_sadness.predict(X_train)\n",
    "print(\"SVR sadness train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_joy, \n",
    "        data_int_joy,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "svr_joy.fit(X_train,y_train)\n",
    "y_pred = svr_joy.predict(X_test)\n",
    "print(\"SVR joy MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = svr_joy.predict(X_train)\n",
    "print(\"SVR joy train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tg7797/anaconda2/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVR anger MSE', 0.0946643222897825)\n",
      "('SVR anger train MSE', 0.0936490618578413)\n",
      "('MLP fear MSE', 0.06697699408464043)\n",
      "('MLP fear train MSE', 0.008870261176981378)\n",
      "('MLP sadness MSE', 0.2314787859402415)\n",
      "('MLP sadness train MSE', 0.22167894835795152)\n",
      "('MLP joy MSE', 0.0460406390297131)\n",
      "('MLP joy train MSE', 0.04623777216197536)\n",
      "39.8997709751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_anger = MLPRegressor(hidden_layer_sizes=(15,2 ))\n",
    "mlp_fear = MLPRegressor(hidden_layer_sizes=(15,2 ))\n",
    "mlp_sadness = MLPRegressor(hidden_layer_sizes=(15,2 ))\n",
    "mlp_joy = MLPRegressor(hidden_layer_sizes=(15,2 ))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_anger, \n",
    "        data_int_anger,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "mlp_anger.fit(X_train,y_train)\n",
    "y_pred = mlp_anger.predict(X_test)\n",
    "print(\"SVR anger MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = mlp_anger.predict(X_train)\n",
    "print(\"SVR anger train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_fear, \n",
    "        data_int_fear,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "mlp_fear.fit(X_train,y_train)\n",
    "y_pred = mlp_fear.predict(X_test)\n",
    "print(\"MLP fear MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = mlp_fear.predict(X_train)\n",
    "print(\"MLP fear train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_sadness, \n",
    "        data_int_sadness,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "mlp_sadness.fit(X_train,y_train)\n",
    "y_pred = mlp_sadness.predict(X_test)\n",
    "print(\"MLP sadness MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = mlp_sadness.predict(X_train)\n",
    "print(\"MLP sadness train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_joy, \n",
    "        data_int_joy,\n",
    "        train_size=0.80, test_size=0.20, \n",
    "        random_state=1234)\n",
    "mlp_joy.fit(X_train,y_train)\n",
    "y_pred = mlp_joy.predict(X_test)\n",
    "print(\"MLP joy MSE\",mean_squared_error(y_test,y_pred))\n",
    "y_pred_train = mlp_joy.predict(X_train)\n",
    "print(\"MLP joy train MSE\",mean_squared_error(y_train,y_pred_train))\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training error is:', 0.002253079001659997)\n",
      "('Testing error is:', 0.030640771163033063)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "start = time.time()\n",
    "ridge.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "print(\"Training error is:\", mean_squared_error(y_train,y_pred_train))\n",
    "print(\"Testing error is:\", mean_squared_error(y_test,y_pred))\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tg(str):\n",
    "    b = vectorizer.transform(str).toarray()\n",
    "    a = lr.predict(b)\n",
    "    intensity = []\n",
    "    for i in range(0,len(a)):\n",
    "        if a[i] == 'sadness':\n",
    "            intensity.append(rfr_sadness.predict([b[i]])[0])\n",
    "        if a[i] == 'joy':\n",
    "            intensity.append(rfr_joy.predict([b[i]])[0])\n",
    "        if a[i] == 'fear':\n",
    "            intensity.append(rfr_fear.predict([b[i]])[0])\n",
    "        if a[i] == 'anger':\n",
    "            intensity.append(rfr_anger.predict([b[i]])[0])\n",
    "    \n",
    "    features_anger = []\n",
    "    features_joy = []\n",
    "    features_sadness = []\n",
    "    features_fear = []\n",
    "    return a,intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['sadness', 'joy', 'fear', 'anger'], dtype='|S7'),\n",
       " [0.6727000000000001, 0.6751, 0.4449000000000001, 0.48739999999999994])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"I am sad \", \"I love you\", \"He missed so many goals\", \"He killed her\"]\n",
    "x = tg(a)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data_labels = []\n",
    "data_int = []\n",
    "\n",
    "dataset=pd.read_csv(\"testing_set/anger-ratings-0to1.test.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('anger')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "    \n",
    "dataset=pd.read_csv(\"testing_set/fear-ratings-0to1.test.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('fear')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "\n",
    "dataset=pd.read_csv(\"testing_set/joy-ratings-0to1.test.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('joy')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "\n",
    "dataset=pd.read_csv(\"testing_set/sadness-ratings-0to1.test.gold.txt\",delimiter=\"\\t\",names=['id','tweet','emotion','intensity'])\n",
    "for i in range(len(dataset)):\n",
    "    data.append(dataset.iat[i,1])\n",
    "    data_labels.append('sadness')\n",
    "    data_int.append(dataset.iat[i,3])\n",
    "    \n",
    "from random import shuffle\n",
    "dv = []\n",
    "dl = []\n",
    "di = []\n",
    "index_shuf = list(range(len(data)))\n",
    "shuffle(index_shuf)\n",
    "for i in index_shuf:\n",
    "    dv.append(data[i])\n",
    "    dl.append(data_labels[i])\n",
    "    di.append(data_int[i])\n",
    "data = dv\n",
    "data_labels = dl\n",
    "data_int = di\n",
    "\n",
    "\n",
    "features = vectorizer.transform(\n",
    "    data\n",
    ")\n",
    "test = features.toarray() # for easy usage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean Squared error on test set = ', 0.03277340866078876)\n",
      "('Classification accuracy on test set = ', 0.7527052832590706)\n"
     ]
    }
   ],
   "source": [
    "a = lr_l1.predict(test)\n",
    "intensity = []\n",
    "for i in range(0,len(a)):\n",
    "    if a[i] == 'sadness':\n",
    "        intensity.append(rfr_sadness.predict([test[i]])[0])\n",
    "    if a[i] == 'joy':\n",
    "        intensity.append(rfr_joy.predict([test[i]])[0])\n",
    "    if a[i] == 'fear':\n",
    "        intensity.append(rfr_fear.predict([test[i]])[0])\n",
    "    if a[i] == 'anger':\n",
    "        intensity.append(rfr_anger.predict([test[i]])[0])\n",
    "        \n",
    "        \n",
    "print(\"Mean Squared error on test set = \",mean_squared_error(intensity,data_int))\n",
    "print(\"Classification accuracy on test set = \",lr.score(test,data_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Don't join @BTCare they put the phone down on you, talk over you and are rude. Taking money out of my acc willynilly! #fuming\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
